{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2275763,"sourceType":"datasetVersion","datasetId":1370616},{"sourceId":7247840,"sourceType":"datasetVersion","datasetId":4198907}],"dockerImageVersionId":30627,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"250\" align=\"center\">\n\n*TRABAJO FINAL - VISIÓN POR COMPUTADORA II - JUAN I. MUNAR*\n\n#### **SKIN CANCER: HAM10000**\n#### PARTE 2 DE 2","metadata":{"id":"7Ff23uCVWbBS"}},{"cell_type":"markdown","source":"##### **3.2. UNDERSAMPLING Y OVERSAMPLING**\n\nSe continuará el análisis iniciado en la parte 1 modificando el tratamiento de los datos desbalanceados, realizando undersampling y oversampling","metadata":{"id":"N_OCFGD9WbBV"}},{"cell_type":"code","source":"# Librerías básicas\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport matplotlib.image as mpimg\nimport os","metadata":{"id":"93muPP7ZWbBW","execution":{"iopub.status.busy":"2023-12-20T20:06:24.839739Z","iopub.execute_input":"2023-12-20T20:06:24.840037Z","iopub.status.idle":"2023-12-20T20:06:25.183936Z","shell.execute_reply.started":"2023-12-20T20:06:24.840011Z","shell.execute_reply":"2023-12-20T20:06:25.183119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ubicaciones y df con One Hot Encoding de clases para cada imagen\nimage_dir = \"/kaggle/input/ham1000-segmentation-and-classification/images\"\nmask_dir = \"/kaggle/input/ham1000-segmentation-and-classification/masks\"\ndf = pd.read_csv(\"/kaggle/input/ham1000-segmentation-and-classification/GroundTruth.csv\")","metadata":{"id":"a2tbiQI7WbBW","execution":{"iopub.status.busy":"2023-12-20T20:06:25.185344Z","iopub.execute_input":"2023-12-20T20:06:25.185731Z","iopub.status.idle":"2023-12-20T20:06:25.223260Z","shell.execute_reply.started":"2023-12-20T20:06:25.185705Z","shell.execute_reply":"2023-12-20T20:06:25.222564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Obtención de labels de las columnas\ndf['label'] = df.drop(columns = [\"image\"], axis = 1).idxmax(axis=1)","metadata":{"id":"auKM-9U4WbBX","execution":{"iopub.status.busy":"2023-12-20T20:06:25.224361Z","iopub.execute_input":"2023-12-20T20:06:25.224965Z","iopub.status.idle":"2023-12-20T20:06:25.244883Z","shell.execute_reply.started":"2023-12-20T20:06:25.224931Z","shell.execute_reply":"2023-12-20T20:06:25.244086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ordeno las columnas\norden_columnas = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC', 'image', 'label']\nclases = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC']\ndf = df[orden_columnas]","metadata":{"id":"fNwduvchWbBY","execution":{"iopub.status.busy":"2023-12-20T20:06:25.246995Z","iopub.execute_input":"2023-12-20T20:06:25.247329Z","iopub.status.idle":"2023-12-20T20:06:25.254454Z","shell.execute_reply.started":"2023-12-20T20:06:25.247304Z","shell.execute_reply":"2023-12-20T20:06:25.253597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creo directorios en kaggle\n!mkdir -p datasets/train datasets/test\n%cd /kaggle/working/datasets/train\n!mkdir AKIEC BCC BKL DF MEL NV VASC\n%ls\n\n%cd /kaggle/working/datasets/test\n!mkdir AKIEC BCC BKL DF MEL NV VASC\n%ls\n\n%cd /kaggle/working","metadata":{"id":"-v6uOHC2WbBY","execution":{"iopub.status.busy":"2023-12-20T20:06:25.255788Z","iopub.execute_input":"2023-12-20T20:06:25.256145Z","iopub.status.idle":"2023-12-20T20:06:30.148609Z","shell.execute_reply.started":"2023-12-20T20:06:25.256114Z","shell.execute_reply":"2023-12-20T20:06:30.147621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Recorto las clases a un valor máximo\nmax_size = 600\n\nfor clase in clases:\n    n_0 = sum(df[clase])\n    if n_0 > max_size:\n        n_filas_eliminar = int(n_0 - max_size)\n        indices_eliminar = df[df[clase] == 1].sample(n_filas_eliminar).index\n        df = df.drop(indices_eliminar)\ndf.label.value_counts()","metadata":{"id":"8xxM2D5-WbBY","execution":{"iopub.status.busy":"2023-12-20T20:06:30.150244Z","iopub.execute_input":"2023-12-20T20:06:30.151010Z","iopub.status.idle":"2023-12-20T20:06:30.183941Z","shell.execute_reply.started":"2023-12-20T20:06:30.150969Z","shell.execute_reply":"2023-12-20T20:06:30.183128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Divido el dataframe en X (nombre de las imágenes) e y (clase)\nfrom sklearn.model_selection import train_test_split\nX = df['image']\ny = df\nX_train, X_test, y_train, y_test = train_test_split(X,\n                                                    df,\n                                                    test_size=0.1,\n                                                    random_state=42,\n                                                    stratify=df['label'])","metadata":{"id":"61vh6Sd5WbBZ","execution":{"iopub.status.busy":"2023-12-20T20:06:30.185138Z","iopub.execute_input":"2023-12-20T20:06:30.185794Z","iopub.status.idle":"2023-12-20T20:06:30.667057Z","shell.execute_reply.started":"2023-12-20T20:06:30.185746Z","shell.execute_reply":"2023-12-20T20:06:30.666076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Hago un oversampling de las clases minoritarias.","metadata":{"id":"qlmoo3c9WbBZ"}},{"cell_type":"code","source":"# Resampleo categóricamente (SMOTEN)\nfrom imblearn.over_sampling import SMOTEN\nsampler = SMOTEN(random_state=0)\nX = y_train.drop(columns=['label'], axis=1)\ny = y_train['label']\n\nX_res, y_res = sampler.fit_resample(X, y)","metadata":{"id":"bEJwLb2iWbBZ","execution":{"iopub.status.busy":"2023-12-20T20:06:30.668657Z","iopub.execute_input":"2023-12-20T20:06:30.669041Z","iopub.status.idle":"2023-12-20T20:06:31.610926Z","shell.execute_reply.started":"2023-12-20T20:06:30.669008Z","shell.execute_reply":"2023-12-20T20:06:31.610137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Actualizo X_train\nX_train = X_res['image']","metadata":{"id":"-DdoVWrzWbBZ","execution":{"iopub.status.busy":"2023-12-20T20:06:31.612092Z","iopub.execute_input":"2023-12-20T20:06:31.612455Z","iopub.status.idle":"2023-12-20T20:06:31.616651Z","shell.execute_reply.started":"2023-12-20T20:06:31.612429Z","shell.execute_reply":"2023-12-20T20:06:31.615747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importo las imágenes\nimport shutil\nfor clase in clases:\n    imgs_name = X_train[X_res[clase]==1].to_list()\n    for img in imgs_name:\n        shutil.copy(f'/kaggle/input/ham1000-segmentation-and-classification/images/{img}.jpg',\n                    f'/kaggle/working/datasets/train/{clase}')\n\nfor clase in clases:\n    imgs_name = X_test[y_test[clase]==1].to_list()\n    for img in imgs_name:\n        shutil.copy(f'/kaggle/input/ham1000-segmentation-and-classification/images/{img}.jpg',\n                    f'/kaggle/working/datasets/test/{clase}')","metadata":{"id":"c4nf-fJRWbBZ","execution":{"iopub.status.busy":"2023-12-20T20:06:31.621247Z","iopub.execute_input":"2023-12-20T20:06:31.621493Z","iopub.status.idle":"2023-12-20T20:07:09.420569Z","shell.execute_reply.started":"2023-12-20T20:06:31.621472Z","shell.execute_reply":"2023-12-20T20:07:09.419728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Chequeo el split\n%ls /kaggle/working/datasets/train/*/* | wc -l\n%ls /kaggle/working/datasets/test/*/* | wc -l","metadata":{"id":"_E84EVmdWbBZ","execution":{"iopub.status.busy":"2023-12-20T20:07:09.422013Z","iopub.execute_input":"2023-12-20T20:07:09.422373Z","iopub.status.idle":"2023-12-20T20:07:11.332290Z","shell.execute_reply.started":"2023-12-20T20:07:09.422339Z","shell.execute_reply":"2023-12-20T20:07:11.331283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### **3.2.1. TRANSFER LEARNING**\n\nSe probarán a continuación diferentes arquitecturas de clasificación clásicas sobre las cuales se hará transfer learning. La idea es aprovechar las capas que captan bordes, colores y texturas para utilizarlas en nuestro problema.\n\nEs la intención realizar data augmentation en todos los casos para tener más datos a la vez que se tengan en cuenta diferencias de coloración, rotación, tamaño, etc. Se incluye este paso para cada punto en particular para adaptar las imágenes a los modelos preentrenados.","metadata":{"id":"T7qla-VIWbBZ"}},{"cell_type":"markdown","source":"##### *3.2.1.1. VGG19*\n\nLos detalles de la red se pueden leer en los siguientes docs [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556).","metadata":{"id":"JukC09pLWbBZ"}},{"cell_type":"code","source":"# Cargo el modelo descargado previamente\nimport torch\nfrom torchvision import models\n\n# Ruta al archivo del modelo preentrenado en Kaggle\nmodelo_ruta = \"/kaggle/input/modelos-tf/vgg19-dcbb9e9d.pth\"\n\n# Cargar el modelo desde el archivo\nvgg19 = models.vgg19(weights=None)\nstate_dict = torch.load(modelo_ruta)\nvgg19.load_state_dict(state_dict)","metadata":{"id":"Aa6HqfV-WbBZ","execution":{"iopub.status.busy":"2023-12-20T20:07:11.333688Z","iopub.execute_input":"2023-12-20T20:07:11.334004Z","iopub.status.idle":"2023-12-20T20:07:21.736516Z","shell.execute_reply.started":"2023-12-20T20:07:11.333975Z","shell.execute_reply":"2023-12-20T20:07:21.735710Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision\nfrom torchvision.transforms import v2\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader#, WeightedRandomSampler\n\n# Utilizo la versión v2 de torchvision.transform\ntransform_train = v2.Compose([\n    v2.RandomResizedCrop(224),\n    v2.RandomHorizontalFlip(0.5),\n    v2.ColorJitter(saturation=0.1, hue=0.1),\n    v2.RandomRotation(45),\n    v2.ToTensor(),\n    v2.Normalize(mean=[0.485, 0.456, 0.406],\n                 std=[0.229, 0.224, 0.225]),\n])\n\n# Transformaciones de test\ntransform_test = v2.Compose([\n    v2.Resize(256),\n    v2.CenterCrop(224),\n    v2.ToTensor(),\n    v2.Normalize(mean=[0.485, 0.456, 0.406],\n                 std=[0.229, 0.224, 0.225]),\n])\n\n# Cargo datasets\ntrain_dataset = torchvision.datasets.ImageFolder(\n    root='/kaggle/working/datasets/train',\n    transform=transform_train\n)\ntest_dataset = torchvision.datasets.ImageFolder(\n    root='/kaggle/working/datasets/test',\n    transform=transform_test\n)\n\n# Cargo DataLoaders\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=32,\n    #sampler=train_sampler,\n    shuffle=True, # shuffle=True es incompatible con sampler\n    num_workers=4,\n    pin_memory=True\n)\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=32,\n    #sampler=test_sampler,\n    shuffle=True,\n    num_workers=4\n)","metadata":{"id":"QtNwYiuZWbBZ","execution":{"iopub.status.busy":"2023-12-20T20:07:21.737973Z","iopub.execute_input":"2023-12-20T20:07:21.738638Z","iopub.status.idle":"2023-12-20T20:07:21.846358Z","shell.execute_reply.started":"2023-12-20T20:07:21.738608Z","shell.execute_reply":"2023-12-20T20:07:21.845470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Congelo todas las capas de la red\nfor param in vgg19.parameters():\n    param.requires_grad = False","metadata":{"id":"LcJ5GZVCWbBZ","execution":{"iopub.status.busy":"2023-12-20T20:07:21.847576Z","iopub.execute_input":"2023-12-20T20:07:21.847890Z","iopub.status.idle":"2023-12-20T20:07:21.852339Z","shell.execute_reply.started":"2023-12-20T20:07:21.847866Z","shell.execute_reply":"2023-12-20T20:07:21.851406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Modifico la última capa para adaptarse al número de clases de tu conjunto de datos\nimport torch.nn as nn\n\nnum_classes = len(train_dataset.classes)\nlast_layer_in_features = vgg19.classifier[-1].in_features\nvgg19.classifier[-1] = torch.nn.Linear(\n    in_features=last_layer_in_features,\n    out_features=num_classes\n)","metadata":{"id":"CfIEzohYWbBZ","execution":{"iopub.status.busy":"2023-12-20T20:07:21.853464Z","iopub.execute_input":"2023-12-20T20:07:21.853731Z","iopub.status.idle":"2023-12-20T20:07:21.864653Z","shell.execute_reply.started":"2023-12-20T20:07:21.853709Z","shell.execute_reply":"2023-12-20T20:07:21.863929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defino la función de entrenamiento\ndef train(model, optimizer, criterion, metric, data, epochs, tb_writer=None):\n\n    train_loader = data[\"train\"]\n    valid_loader = data[\"valid\"]\n\n    train_writer = tb_writer[\"train\"]\n    valid_writer = tb_writer[\"valid\"]\n\n    if tb_writer:\n        train_writer.add_graph(model,\n                               torch.zeros((1, 3, data[\"image_width\"],\n                                            data[\"image_height\"])))\n        valid_writer.add_graph(model,\n                               torch.zeros((1, 3, data[\"image_width\"],\n                                            data[\"image_height\"])))\n\n    if torch.cuda.is_available():\n        model.to(\"cuda\")\n        metric.to(\"cuda\")\n\n    train_loss = []\n    train_met = []\n    valid_loss = []\n    valid_met = []\n\n    best_val_loss = float('inf')\n\n    for epoch in range(epochs):\n\n        # Pongo el modelo en modo entrenamiento\n        model.train()\n\n        epoch_train_loss = 0.0\n        epoch_train_metric = 0.0\n\n        for train_data, train_target in train_loader:\n\n            if torch.cuda.is_available():\n                train_data = train_data.to(\"cuda\")\n                train_target = train_target.to(\"cuda\")\n\n            optimizer.zero_grad()\n            output = model(train_data.float())\n            loss = criterion(output, train_target)\n            epoch_train_loss += loss.item()\n            loss.backward()\n            optimizer.step()\n\n            metric_ = metric(output, train_target)\n            epoch_train_metric += metric_.item()\n\n        epoch_train_loss = epoch_train_loss / len(train_loader)\n        epoch_train_metric = epoch_train_metric / len(train_loader)\n        train_loss.append(epoch_train_loss)\n        train_met.append(epoch_train_metric)\n\n        # Pongo el modelo en modo testeo\n        model.eval()\n\n        epoch_valid_loss = 0.0\n        epoch_valid_metric = 0.0\n\n        for valid_data, valid_target in valid_loader:\n            if torch.cuda.is_available():\n                valid_data = valid_data.to(\"cuda\")\n                valid_target = valid_target.to(\"cuda\")\n\n            output = model(valid_data.float())\n            epoch_valid_loss += criterion(output, valid_target).item()\n            epoch_valid_metric += metric(output, valid_target).item()\n\n        epoch_valid_loss = epoch_valid_loss / len(valid_loader)\n        epoch_valid_metric = epoch_valid_metric / len(valid_loader)\n        valid_loss.append(epoch_valid_loss)\n        valid_met.append(epoch_valid_metric)\n\n        if epoch_valid_loss < best_val_loss:\n            best_val_loss = epoch_valid_loss\n            best_params = model.state_dict()\n\n        print(\"Epoch: {}/{} - Train loss {:.6f} - Train metric {:.6f} - Valid Loss {:.6f} - Valid metric {:.6f}\".format(\n        epoch+1, epochs, epoch_train_loss, epoch_train_metric, epoch_valid_loss, epoch_valid_metric))\n\n        if tb_writer:\n            train_writer.add_scalar(\"loss\", epoch_train_loss, epoch)\n            valid_writer.add_scalar(\"loss\", epoch_valid_loss, epoch)\n            train_writer.add_scalar(\"metric\", epoch_train_metric, epoch)\n            valid_writer.add_scalar(\"metric\", epoch_valid_metric, epoch)\n            train_writer.flush()\n            valid_writer.flush()\n\n    history = {}\n    history[\"train_loss\"] = train_loss\n    history[\"train_met\"] = train_met\n    history[\"valid_loss\"] = valid_loss\n    history[\"valid_met\"] = valid_met\n\n    torch.save(best_params, 'best_model_params.pth')\n\n    return history","metadata":{"id":"3d353hENWbBZ","execution":{"iopub.status.busy":"2023-12-20T20:07:21.866001Z","iopub.execute_input":"2023-12-20T20:07:21.866324Z","iopub.status.idle":"2023-12-20T20:07:21.882411Z","shell.execute_reply.started":"2023-12-20T20:07:21.866294Z","shell.execute_reply":"2023-12-20T20:07:21.881524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Alto y ancho de imágenes\nH = 256\nW = 256","metadata":{"id":"EUsGb6MGWbBa","execution":{"iopub.status.busy":"2023-12-20T20:07:21.883710Z","iopub.execute_input":"2023-12-20T20:07:21.884259Z","iopub.status.idle":"2023-12-20T20:07:21.894663Z","shell.execute_reply.started":"2023-12-20T20:07:21.884233Z","shell.execute_reply":"2023-12-20T20:07:21.893925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Corremos el entrenamiento\nimport torchmetrics\nfrom torch.utils.tensorboard import SummaryWriter\nimport torch.optim as optim\n\noptimizer = torch.optim.Adam(vgg19.parameters(), lr=0.0001)\nloss = torch.nn.CrossEntropyLoss()\nmetric = torchmetrics.F1Score(task='multiclass', num_classes=num_classes)\ndata = {\"train\": train_loader,\n        \"valid\": test_loader,\n        \"image_width\": W,\n        \"image_height\": H}\nepochs = 50\nwriter = {\"train\": SummaryWriter(log_dir=\"transfer_learning_vgg/train\"),\n          \"valid\": SummaryWriter(log_dir=\"transfer_learning_vgg/valid\")}\n\nhistory = train(vgg19,\n                optimizer,\n                loss,\n                metric,\n                data,\n                epochs,\n                writer)","metadata":{"id":"nufk_GAxWbBa","execution":{"iopub.status.busy":"2023-12-20T20:07:21.895633Z","iopub.execute_input":"2023-12-20T20:07:21.895898Z","iopub.status.idle":"2023-12-20T20:21:18.243479Z","shell.execute_reply.started":"2023-12-20T20:07:21.895877Z","shell.execute_reply":"2023-12-20T20:21:18.242192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ploteo\nfig, axs = plt.subplots(2, 1, figsize=(10, 10))\n\naxs[0].plot(history[\"train_loss\"])\naxs[0].plot(history[\"valid_loss\"])\naxs[0].title.set_text('Error de Entrenamiento vs Validación')\naxs[0].legend(['Train', 'Valid'])\n\naxs[1].plot(history[\"train_met\"])\naxs[1].plot(history[\"valid_met\"])\naxs[1].title.set_text('F1 de Entrenamiento vs Validación')\naxs[1].legend(['Train', 'Valid'])","metadata":{"id":"ihwaQaOvWbBa","execution":{"iopub.status.busy":"2023-12-20T20:21:18.245483Z","iopub.execute_input":"2023-12-20T20:21:18.246865Z","iopub.status.idle":"2023-12-20T20:21:18.841368Z","shell.execute_reply.started":"2023-12-20T20:21:18.246821Z","shell.execute_reply":"2023-12-20T20:21:18.840431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cargo los mejores parámetros (min loss)\nbest_model_params = torch.load('best_model_params.pth')\nvgg19.load_state_dict(best_model_params)","metadata":{"id":"RQbq8nl3WbBa","execution":{"iopub.status.busy":"2023-12-20T20:21:18.842784Z","iopub.execute_input":"2023-12-20T20:21:18.843379Z","iopub.status.idle":"2023-12-20T20:21:19.297258Z","shell.execute_reply.started":"2023-12-20T20:21:18.843344Z","shell.execute_reply":"2023-12-20T20:21:19.296347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluación del accuracy y Confusion Matrix\nfrom torchmetrics.classification import MulticlassConfusionMatrix\n\nall_labels = []\nall_preds = []\n\n# Todo debe correr en el mismo sitio\ndevice = 'cuda'\n\n# Aseguro el modelo en evaluation\nvgg19.to(device)\nvgg19.eval()\n\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = vgg19(inputs)\n        _, preds = torch.max(outputs, 1)\n\n        all_labels.extend(labels.cpu().numpy())\n        all_preds.extend(preds.cpu().numpy())\n\nconfmat = MulticlassConfusionMatrix(num_classes=num_classes)\nconfmat(torch.tensor(all_preds),\n        torch.tensor(all_labels))","metadata":{"id":"sdzO2VjykNva","execution":{"iopub.status.busy":"2023-12-20T20:21:19.298397Z","iopub.execute_input":"2023-12-20T20:21:19.298659Z","iopub.status.idle":"2023-12-20T20:21:21.055327Z","shell.execute_reply.started":"2023-12-20T20:21:19.298636Z","shell.execute_reply":"2023-12-20T20:21:21.054231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ploteo la matriz de confusion\nax_ = clases\nfig_, ax_ = confmat.plot()\n\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\n\nax_.set_xticklabels(clases)\nplt.xticks(rotation=45)\nax_.set_yticklabels(clases)\nplt.yticks(rotation=45)\n\nplt.title(\"Confusion Matrix\")\nplt.show()","metadata":{"id":"XHcB6x2TkUvC","execution":{"iopub.status.busy":"2023-12-20T20:21:21.057083Z","iopub.execute_input":"2023-12-20T20:21:21.057954Z","iopub.status.idle":"2023-12-20T20:21:21.380723Z","shell.execute_reply.started":"2023-12-20T20:21:21.057916Z","shell.execute_reply":"2023-12-20T20:21:21.379805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluación del accuracy\nvgg19.eval()\n\ncorrectas = 0\ntotal = 0\ndevice = 'cuda'\n\nwith torch.no_grad():\n    for imagenes, etiquetas in test_loader:\n        imagenes, etiquetas = imagenes.to(device), etiquetas.to(device)\n        salidas = vgg19(imagenes)\n        _, predicciones = torch.max(salidas.data, 1)\n        total += etiquetas.size(0)\n        correctas += (predicciones == etiquetas).sum().item()\n\n# Calcular el accuracy\naccuracy = correctas / total\nprint(f'Accuracy en el conjunto de pruebas: {accuracy * 100:.2f}%')","metadata":{"id":"dQqFgje8WbBa","execution":{"iopub.status.busy":"2023-12-20T20:21:21.382143Z","iopub.execute_input":"2023-12-20T20:21:21.382645Z","iopub.status.idle":"2023-12-20T20:21:23.190285Z","shell.execute_reply.started":"2023-12-20T20:21:21.382610Z","shell.execute_reply":"2023-12-20T20:21:23.188992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evalúo el accuracy por clase\nvgg19.eval()  # Asegurarte de que el modelo esté en modo de evaluación\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nvgg19.to(device)\n\ncorrect_predictions_per_class = {i: 0 for i in range(num_classes)}\ntotal_samples_per_class = {i: 0 for i in range(num_classes)}\n\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        outputs = vgg19(inputs)\n        _, predicted_classes = torch.max(outputs, 1)\n\n        for i in range(len(labels)):\n            label = labels[i].item()\n            prediction = predicted_classes[i].item()\n            total_samples_per_class[label] += 1\n            correct_predictions_per_class[label] += int(label == prediction)\n\nclass_accuracies = {}\nfor class_label, correct_predictions in correct_predictions_per_class.items():\n    total_samples = total_samples_per_class[class_label]\n    accuracy = correct_predictions / total_samples if total_samples > 0 else 0.0\n    class_accuracies[class_label] = accuracy\n\nfor class_label, accuracy in class_accuracies.items():\n    print(f'Accuracy for Class {clases[class_label]}: {accuracy:.2%}')","metadata":{"id":"NFFQLZbuWbBa","execution":{"iopub.status.busy":"2023-12-20T20:21:23.191962Z","iopub.execute_input":"2023-12-20T20:21:23.192360Z","iopub.status.idle":"2023-12-20T20:21:25.062547Z","shell.execute_reply.started":"2023-12-20T20:21:23.192321Z","shell.execute_reply":"2023-12-20T20:21:25.061509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Salvo el modelo y el estado del optimizador\nruta_modelo_completo = '/kaggle/working/vgg19'\ntorch.save({\n    'modelo_estado_dict': vgg19.state_dict(),\n    'optimizador_estado_dict': optimizer.state_dict(),\n}, ruta_modelo_completo)","metadata":{"id":"xWmmpnavWbBa","execution":{"iopub.status.busy":"2023-12-20T20:21:25.064361Z","iopub.execute_input":"2023-12-20T20:21:25.065293Z","iopub.status.idle":"2023-12-20T20:21:26.094793Z","shell.execute_reply.started":"2023-12-20T20:21:25.065251Z","shell.execute_reply":"2023-12-20T20:21:26.093810Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"El resultado no es bueno.","metadata":{"id":"xwyAdsmWWbBa"}},{"cell_type":"markdown","source":"##### *3.2.1.2. ResNet50*\n\nProbemos ajustar la red ResNet50, esta vez utilizando descargas directas.\n\nLos detalles de la red se pueden encontrar en [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)","metadata":{"id":"8ipdge0IWbBa"}},{"cell_type":"code","source":"# Importo ResNet50\nfrom torchvision.models import resnet50\n\n# Ruta al archivo del modelo preentrenado en Kaggle\nmodelo_ruta = \"/kaggle/input/modelos-tf/resnet50-11ad3fa6.pth\"\n\n# Cargar el modelo desde el archivo\nresnet50_model = models.resnet50(weights=None)\nstate_dict = torch.load(modelo_ruta)\nresnet50_model.load_state_dict(state_dict)","metadata":{"id":"3g8YAealWbBa","execution":{"iopub.status.busy":"2023-12-20T20:21:26.096030Z","iopub.execute_input":"2023-12-20T20:21:26.096327Z","iopub.status.idle":"2023-12-20T20:21:27.530513Z","shell.execute_reply.started":"2023-12-20T20:21:26.096303Z","shell.execute_reply":"2023-12-20T20:21:27.529555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision\nfrom torchvision.transforms import v2\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\n\n# Utilizo la versión v2 de torchvision.transform\ntransform_train = v2.Compose([\n    v2.RandomResizedCrop(224),\n    v2.RandomHorizontalFlip(0.5),\n    v2.ColorJitter(saturation=0.1, hue=0.1),\n    v2.RandomRotation(45),\n    v2.ToTensor(),\n    v2.Normalize(mean=[0.485, 0.456, 0.406],\n                 std=[0.229, 0.224, 0.225]),\n])\n\n# Transformaciones de test\ntransform_test = v2.Compose([\n    v2.Resize(232),\n    v2.CenterCrop(224),\n    v2.ToTensor(),\n    v2.Normalize(mean=[0.485, 0.456, 0.406],\n                 std=[0.229, 0.224, 0.225]),\n])\n\n# Cargo datasets\ntrain_dataset = torchvision.datasets.ImageFolder(\n    root='/kaggle/working/datasets/train',\n    transform=transform_train\n)\ntest_dataset = torchvision.datasets.ImageFolder(\n    root='/kaggle/working/datasets/test',\n    transform=transform_test\n)\n\n# Cargo DataLoaders\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=64,\n    shuffle=True,\n    #sampler=train_sampler,\n    num_workers=4,\n    pin_memory=True\n)\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=64,\n    #sampler=test_sampler,\n    shuffle=True,\n    num_workers=4\n)","metadata":{"id":"Gas2KxMsWbBd","execution":{"iopub.status.busy":"2023-12-20T20:21:27.531968Z","iopub.execute_input":"2023-12-20T20:21:27.532559Z","iopub.status.idle":"2023-12-20T20:21:27.558806Z","shell.execute_reply.started":"2023-12-20T20:21:27.532521Z","shell.execute_reply":"2023-12-20T20:21:27.557957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Congelo todas las capas de la red\nfor param in resnet50_model.parameters():\n    param.requires_grad = False","metadata":{"id":"lmAGOjPeWbBd","execution":{"iopub.status.busy":"2023-12-20T20:21:27.566974Z","iopub.execute_input":"2023-12-20T20:21:27.567242Z","iopub.status.idle":"2023-12-20T20:21:27.572277Z","shell.execute_reply.started":"2023-12-20T20:21:27.567220Z","shell.execute_reply":"2023-12-20T20:21:27.571399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Modifico la última capa para adaptarse al número de clases de tu conjunto de datos\nimport torch.nn as nn\n\nnum_classes = len(train_dataset.classes)\nlast_layer_in_features = resnet50_model.fc.in_features\nresnet50_model.fc = torch.nn.Linear(\n    in_features=last_layer_in_features,\n    out_features=num_classes\n)","metadata":{"id":"lkhmjZIZWbBe","execution":{"iopub.status.busy":"2023-12-20T20:21:27.573534Z","iopub.execute_input":"2023-12-20T20:21:27.574155Z","iopub.status.idle":"2023-12-20T20:21:27.581915Z","shell.execute_reply.started":"2023-12-20T20:21:27.574121Z","shell.execute_reply":"2023-12-20T20:21:27.581206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Alto y ancho de imágenes\nH = 232\nW = 232","metadata":{"id":"d5D8mdjDWbBe","execution":{"iopub.status.busy":"2023-12-20T20:21:27.582991Z","iopub.execute_input":"2023-12-20T20:21:27.583298Z","iopub.status.idle":"2023-12-20T20:21:27.595099Z","shell.execute_reply.started":"2023-12-20T20:21:27.583275Z","shell.execute_reply":"2023-12-20T20:21:27.594315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Corremos el entrenamiento\nimport torchmetrics\nfrom torch.utils.tensorboard import SummaryWriter\nimport torch.optim as optim\n\noptimizer = torch.optim.Adam(resnet50_model.parameters(), lr=0.00001)\nloss = torch.nn.CrossEntropyLoss()\nmetric = torchmetrics.F1Score(task='multiclass', num_classes=num_classes)\ndata = {\"train\": train_loader,\n        \"valid\": test_loader,\n        \"image_width\": W,\n        \"image_height\": H}\nepochs = 50\nwriter = {\"train\": SummaryWriter(log_dir=\"transfer_learning_RN50/train\"),\n          \"valid\": SummaryWriter(log_dir=\"transfer_learning_RN50/valid\")}\n\nhistory = train(resnet50_model,\n                optimizer,\n                loss,\n                metric,\n                data,\n                epochs,\n                writer)","metadata":{"id":"wRj2DCTqWbBe","execution":{"iopub.status.busy":"2023-12-20T20:21:27.596121Z","iopub.execute_input":"2023-12-20T20:21:27.596404Z","iopub.status.idle":"2023-12-20T20:34:32.297227Z","shell.execute_reply.started":"2023-12-20T20:21:27.596371Z","shell.execute_reply":"2023-12-20T20:34:32.295942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ploteo\nfig, axs = plt.subplots(2, 1, figsize=(10, 10))\n\naxs[0].plot(history[\"train_loss\"])\naxs[0].plot(history[\"valid_loss\"])\naxs[0].title.set_text('Error de Entrenamiento vs Validación')\naxs[0].legend(['Train', 'Valid'])\n\naxs[1].plot(history[\"train_met\"])\naxs[1].plot(history[\"valid_met\"])\naxs[1].title.set_text('F1 de Entrenamiento vs Validación')\naxs[1].legend(['Train', 'Valid'])","metadata":{"id":"3G5TgXcWWbBe","execution":{"iopub.status.busy":"2023-12-20T20:34:32.299654Z","iopub.execute_input":"2023-12-20T20:34:32.300114Z","iopub.status.idle":"2023-12-20T20:34:32.894883Z","shell.execute_reply.started":"2023-12-20T20:34:32.300065Z","shell.execute_reply":"2023-12-20T20:34:32.893921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cargo los mejores parámetros (min loss)\nbest_model_params = torch.load('best_model_params.pth')\nresnet50_model.load_state_dict(best_model_params)","metadata":{"id":"5uV7KXm8WbBe","execution":{"iopub.status.busy":"2023-12-20T20:34:32.896259Z","iopub.execute_input":"2023-12-20T20:34:32.896633Z","iopub.status.idle":"2023-12-20T20:34:33.016222Z","shell.execute_reply.started":"2023-12-20T20:34:32.896586Z","shell.execute_reply":"2023-12-20T20:34:33.015204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluación del accuracy y Confusion Matrix\nfrom torchmetrics.classification import MulticlassConfusionMatrix\n\nall_labels = []\nall_preds = []\n\n# Todo debe correr en el mismo sitio\ndevice = 'cuda'\n\n# Aseguro el modelo en evaluation\nresnet50_model.to(device)\nresnet50_model.eval()\n\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = resnet50_model(inputs)\n        _, preds = torch.max(outputs, 1)\n\n        all_labels.extend(labels.cpu().numpy())\n        all_preds.extend(preds.cpu().numpy())\n\nconfmat = MulticlassConfusionMatrix(num_classes=num_classes)\nconfmat(torch.tensor(all_preds),\n        torch.tensor(all_labels))","metadata":{"id":"4egcr-QukqkK","execution":{"iopub.status.busy":"2023-12-20T20:34:33.017407Z","iopub.execute_input":"2023-12-20T20:34:33.017730Z","iopub.status.idle":"2023-12-20T20:34:34.801868Z","shell.execute_reply.started":"2023-12-20T20:34:33.017702Z","shell.execute_reply":"2023-12-20T20:34:34.800820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ploteo la matriz de confusion\nax_ = clases\nfig_, ax_ = confmat.plot()\n\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\n\nax_.set_xticklabels(clases)\nplt.xticks(rotation=45)\nax_.set_yticklabels(clases)\nplt.yticks(rotation=45)\n\nplt.title(\"Confusion Matrix\")\nplt.show()","metadata":{"id":"ErxXwvEKkqby","execution":{"iopub.status.busy":"2023-12-20T20:34:34.803318Z","iopub.execute_input":"2023-12-20T20:34:34.803628Z","iopub.status.idle":"2023-12-20T20:34:35.123305Z","shell.execute_reply.started":"2023-12-20T20:34:34.803600Z","shell.execute_reply":"2023-12-20T20:34:35.122436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluación del accuracy\nresnet50_model.eval()\n\ncorrectas = 0\ntotal = 0\ndevice = 'cuda'\n\nwith torch.no_grad():\n    for imagenes, etiquetas in test_loader:\n        imagenes, etiquetas = imagenes.to(device), etiquetas.to(device)\n        salidas = resnet50_model(imagenes)\n        _, predicciones = torch.max(salidas.data, 1)\n        total += etiquetas.size(0)\n        correctas += (predicciones == etiquetas).sum().item()\n\n# Calcular el accuracy\naccuracy = correctas / total\nprint(f'Accuracy en el conjunto de pruebas: {accuracy * 100:.2f}%')","metadata":{"id":"_K-C1e9LWbBe","execution":{"iopub.status.busy":"2023-12-20T20:34:35.124738Z","iopub.execute_input":"2023-12-20T20:34:35.125122Z","iopub.status.idle":"2023-12-20T20:34:36.865074Z","shell.execute_reply.started":"2023-12-20T20:34:35.125088Z","shell.execute_reply":"2023-12-20T20:34:36.863849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet50_model.eval()  # Asegurarte de que el modelo esté en modo de evaluación\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nresnet50_model.to(device)\n\ncorrect_predictions_per_class = {i: 0 for i in range(num_classes)}\ntotal_samples_per_class = {i: 0 for i in range(num_classes)}\n\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        outputs = resnet50_model(inputs)\n        _, predicted_classes = torch.max(outputs, 1)\n\n        for i in range(len(labels)):\n            label = labels[i].item()\n            prediction = predicted_classes[i].item()\n            total_samples_per_class[label] += 1\n            correct_predictions_per_class[label] += int(label == prediction)\n\nclass_accuracies = {}\nfor class_label, correct_predictions in correct_predictions_per_class.items():\n    total_samples = total_samples_per_class[class_label]\n    accuracy = correct_predictions / total_samples if total_samples > 0 else 0.0\n    class_accuracies[class_label] = accuracy\n\nfor class_label, accuracy in class_accuracies.items():\n    print(f'Accuracy for Class {clases[class_label]}: {accuracy:.2%}')","metadata":{"id":"Gxp9ObjfWbBe","execution":{"iopub.status.busy":"2023-12-20T20:34:36.866813Z","iopub.execute_input":"2023-12-20T20:34:36.867683Z","iopub.status.idle":"2023-12-20T20:34:38.583256Z","shell.execute_reply.started":"2023-12-20T20:34:36.867640Z","shell.execute_reply":"2023-12-20T20:34:38.582028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Salvo el modelo y el estado del optimizador\nruta_modelo_completo = '/kaggle/working/resnet50'\ntorch.save({\n    'modelo_estado_dict': resnet50_model.state_dict(),\n    'optimizador_estado_dict': optimizer.state_dict(),\n}, ruta_modelo_completo)","metadata":{"id":"-ew6P8xeWbBe","execution":{"iopub.status.busy":"2023-12-20T20:34:38.584692Z","iopub.execute_input":"2023-12-20T20:34:38.585026Z","iopub.status.idle":"2023-12-20T20:34:38.761156Z","shell.execute_reply.started":"2023-12-20T20:34:38.584996Z","shell.execute_reply":"2023-12-20T20:34:38.760281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### *3.2.1.3. Vision Transformer*\n\nProbemos ajustar la red Vision Transformer.\n\nLos detalles de la red se pueden encontrar en: [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)","metadata":{"id":"RrqHxY-_WbBe"}},{"cell_type":"code","source":"from torchvision.models import vit_b_16\n# Ruta al archivo del modelo preentrenado en Kaggle\nmodelo_ruta = \"/kaggle/input/modelos-tf/vit_b_16-c867db91.pth\"\n\n# Cargar el modelo desde el archivo\nvitb16_model = models.vit_b_16(weights=None).to(device)\nstate_dict = torch.load(modelo_ruta)\nvitb16_model.load_state_dict(state_dict)","metadata":{"id":"_xNDM_p2WbBe","execution":{"iopub.status.busy":"2023-12-20T20:34:38.762715Z","iopub.execute_input":"2023-12-20T20:34:38.763441Z","iopub.status.idle":"2023-12-20T20:34:42.632682Z","shell.execute_reply.started":"2023-12-20T20:34:38.763400Z","shell.execute_reply":"2023-12-20T20:34:42.631661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision\nfrom torchvision.transforms import v2\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\n\n# Utilizo la versión v2 de torchvision.transform\ntransform_train = v2.Compose([\n    v2.RandomResizedCrop(224),\n    v2.RandomHorizontalFlip(0.5),\n    v2.ColorJitter(saturation=0.1, hue=0.1),\n    v2.RandomRotation(45),\n    v2.ToTensor(),\n    v2.Normalize(mean=[0.485, 0.456, 0.406],\n                 std=[0.229, 0.224, 0.225]),\n])\n\n# Transformaciones de test\ntransform_test = v2.Compose([\n    v2.Resize(224),\n    v2.CenterCrop(224),\n    v2.ToTensor(),\n    v2.Normalize(mean=[0.485, 0.456, 0.406],\n                 std=[0.229, 0.224, 0.225]),\n])\n\n# Cargo datasets\ntrain_dataset = torchvision.datasets.ImageFolder(\n    root='/kaggle/working/datasets/train',\n    transform=transform_train\n)\ntest_dataset = torchvision.datasets.ImageFolder(\n    root='/kaggle/working/datasets/test',\n    transform=transform_test\n)\n\n# Cargo DataLoaders\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=64,\n    shuffle=True,\n    #sampler=train_sampler,\n    num_workers=4,\n    pin_memory=True\n)\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=64,\n    #sampler=test_sampler,\n    shuffle=True,\n    num_workers=4\n)","metadata":{"id":"Q8FC-S0GWbBe","execution":{"iopub.status.busy":"2023-12-20T20:34:42.633980Z","iopub.execute_input":"2023-12-20T20:34:42.634287Z","iopub.status.idle":"2023-12-20T20:34:42.661796Z","shell.execute_reply.started":"2023-12-20T20:34:42.634261Z","shell.execute_reply":"2023-12-20T20:34:42.660818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Congelo todas las capas de la red\nfor param in vitb16_model.parameters():\n    param.requires_grad = False","metadata":{"id":"yRjt8uH8WbBe","execution":{"iopub.status.busy":"2023-12-20T20:34:42.663117Z","iopub.execute_input":"2023-12-20T20:34:42.663428Z","iopub.status.idle":"2023-12-20T20:34:42.668702Z","shell.execute_reply.started":"2023-12-20T20:34:42.663402Z","shell.execute_reply":"2023-12-20T20:34:42.667824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Se modifica la última capa\nimport torch.nn as nn\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nnum_classes = len(train_dataset.classes)\nvitb16_model.heads = nn.Linear(in_features=768, out_features=num_classes).to(device)","metadata":{"id":"kyvvAijLWbBf","execution":{"iopub.status.busy":"2023-12-20T20:34:42.683682Z","iopub.execute_input":"2023-12-20T20:34:42.684039Z","iopub.status.idle":"2023-12-20T20:34:42.693802Z","shell.execute_reply.started":"2023-12-20T20:34:42.684005Z","shell.execute_reply":"2023-12-20T20:34:42.692966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Alto y ancho de imágenes\nH = 224\nW = 224","metadata":{"id":"QpmtN7ZaWbBf","execution":{"iopub.status.busy":"2023-12-20T20:34:42.695041Z","iopub.execute_input":"2023-12-20T20:34:42.695335Z","iopub.status.idle":"2023-12-20T20:34:42.703712Z","shell.execute_reply.started":"2023-12-20T20:34:42.695310Z","shell.execute_reply":"2023-12-20T20:34:42.702789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Corremos el entrenamiento\nimport torchmetrics\nfrom torch.utils.tensorboard import SummaryWriter\nimport torch.optim as optim\n\noptimizer = torch.optim.Adam(vitb16_model.parameters(), lr=0.00001)\nloss = torch.nn.CrossEntropyLoss()\nmetric = torchmetrics.F1Score(task='multiclass', num_classes=num_classes)\ndata = {\"train\": train_loader,\n        \"valid\": test_loader,\n        \"image_width\": W,\n        \"image_height\": H}\nepochs = 50\nwriter = {\"train\": SummaryWriter(log_dir=\"transfer_learning_ViT/train\"),\n          \"valid\": SummaryWriter(log_dir=\"transfer_learning_ViT/valid\")}\n\nhistory = train(vitb16_model.to('cpu'),\n                optimizer,\n                loss,\n                metric,\n                data,\n                epochs,\n                writer)","metadata":{"id":"Tw5CjgpbWbBf","execution":{"iopub.status.busy":"2023-12-20T20:34:42.704962Z","iopub.execute_input":"2023-12-20T20:34:42.705276Z","iopub.status.idle":"2023-12-20T20:52:10.315797Z","shell.execute_reply.started":"2023-12-20T20:34:42.705252Z","shell.execute_reply":"2023-12-20T20:52:10.314547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ploteo\nfig, axs = plt.subplots(2, 1, figsize=(10, 10))\n\naxs[0].plot(history[\"train_loss\"])\naxs[0].plot(history[\"valid_loss\"])\naxs[0].title.set_text('Error de Entrenamiento vs Validación')\naxs[0].legend(['Train', 'Valid'])\n\naxs[1].plot(history[\"train_met\"])\naxs[1].plot(history[\"valid_met\"])\naxs[1].title.set_text('F1 de Entrenamiento vs Validación')\naxs[1].legend(['Train', 'Valid'])","metadata":{"id":"8EHIvDr5WbBf","execution":{"iopub.status.busy":"2023-12-20T20:52:10.317882Z","iopub.execute_input":"2023-12-20T20:52:10.318658Z","iopub.status.idle":"2023-12-20T20:52:10.888488Z","shell.execute_reply.started":"2023-12-20T20:52:10.318614Z","shell.execute_reply":"2023-12-20T20:52:10.887505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cargo los mejores parámetros (min loss)\nbest_model_params = torch.load('best_model_params.pth')\nvitb16_model.load_state_dict(best_model_params)","metadata":{"id":"q1kcmn3EWbBf","execution":{"iopub.status.busy":"2023-12-20T20:52:10.889922Z","iopub.execute_input":"2023-12-20T20:52:10.890218Z","iopub.status.idle":"2023-12-20T20:52:11.177839Z","shell.execute_reply.started":"2023-12-20T20:52:10.890193Z","shell.execute_reply":"2023-12-20T20:52:11.176806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluación del accuracy y Confusion Matrix\nfrom torchmetrics.classification import MulticlassConfusionMatrix\n\nall_labels = []\nall_preds = []\n\n# Todo debe correr en el mismo sitio\ndevice = 'cuda'\n\n# Aseguro el modelo en evaluation\nvitb16_model.to(device)\nvitb16_model.eval()\n\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = vitb16_model(inputs)\n        _, preds = torch.max(outputs, 1)\n\n        all_labels.extend(labels.cpu().numpy())\n        all_preds.extend(preds.cpu().numpy())\n\nconfmat = MulticlassConfusionMatrix(num_classes=num_classes)\nconfmat(torch.tensor(all_preds),\n        torch.tensor(all_labels))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ploteo la matriz de confusion\nax_ = clases\nfig_, ax_ = confmat.plot()\n\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\n\nax_.set_xticklabels(clases)\nplt.xticks(rotation=45)\nax_.set_yticklabels(clases)\nplt.yticks(rotation=45)\n\nplt.title(\"Confusion Matrix\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluación del accuracy\nvitb16_model.eval()\n\ncorrectas = 0\ntotal = 0\ndevice = 'cuda'\n\nwith torch.no_grad():\n    for imagenes, etiquetas in test_loader:\n        imagenes, etiquetas = imagenes.to(device), etiquetas.to(device)\n        salidas = vitb16_model(imagenes)\n        _, predicciones = torch.max(salidas.data, 1)\n        total += etiquetas.size(0)\n        correctas += (predicciones == etiquetas).sum().item()\n\n# Calcular el accuracy\naccuracy = correctas / total\nprint(f'Accuracy en el conjunto de pruebas: {accuracy * 100:.2f}%')","metadata":{"id":"7lmvmyp-WbBf","execution":{"iopub.status.busy":"2023-12-20T20:52:11.178992Z","iopub.execute_input":"2023-12-20T20:52:11.179300Z","iopub.status.idle":"2023-12-20T20:52:14.174470Z","shell.execute_reply.started":"2023-12-20T20:52:11.179274Z","shell.execute_reply":"2023-12-20T20:52:14.173290Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vitb16_model.eval()  # Asegurarte de que el modelo esté en modo de evaluación\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nvitb16_model.to(device)\n\ncorrect_predictions_per_class = {i: 0 for i in range(num_classes)}\ntotal_samples_per_class = {i: 0 for i in range(num_classes)}\n\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        outputs = vitb16_model(inputs)\n        _, predicted_classes = torch.max(outputs, 1)\n\n        for i in range(len(labels)):\n            label = labels[i].item()\n            prediction = predicted_classes[i].item()\n            total_samples_per_class[label] += 1\n            correct_predictions_per_class[label] += int(label == prediction)\n\nclass_accuracies = {}\nfor class_label, correct_predictions in correct_predictions_per_class.items():\n    total_samples = total_samples_per_class[class_label]\n    accuracy = correct_predictions / total_samples if total_samples > 0 else 0.0\n    class_accuracies[class_label] = accuracy\n\nfor class_label, accuracy in class_accuracies.items():\n    print(f'Accuracy for Class {clases[class_label]}: {accuracy:.2%}')","metadata":{"id":"UH0stmX6WbBf","execution":{"iopub.status.busy":"2023-12-20T20:52:14.176333Z","iopub.execute_input":"2023-12-20T20:52:14.177081Z","iopub.status.idle":"2023-12-20T20:52:17.162149Z","shell.execute_reply.started":"2023-12-20T20:52:14.177036Z","shell.execute_reply":"2023-12-20T20:52:17.160951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Salvo el modelo y el estado del optimizador\nruta_modelo_completo = '/kaggle/working/ViTb16'\ntorch.save({\n    'modelo_estado_dict': vitb16_model.state_dict(),\n    'optimizador_estado_dict': optimizer.state_dict(),\n}, ruta_modelo_completo)","metadata":{"id":"BhnCCo6MWbBf","execution":{"iopub.status.busy":"2023-12-20T20:52:17.164441Z","iopub.execute_input":"2023-12-20T20:52:17.164908Z","iopub.status.idle":"2023-12-20T20:52:17.638315Z","shell.execute_reply.started":"2023-12-20T20:52:17.164863Z","shell.execute_reply":"2023-12-20T20:52:17.637479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### **3.2.2. ENTRENAMIENTO COMPLETO**\n\nSe propone entrenar desde cero una arquitectura convolucional sencilla para evaluar el desempeño. La idea es que no sea lo suficientemente profunda como para requerir conexiones residuales o demasiado tiempo de entrenamiento.","metadata":{"id":"h_gmae4FWbBf"}},{"cell_type":"code","source":"CANTIDAD_CLASES = len(clases)\nANCHO_IMAGENES = 256\nALTO_IMAGENES = 256","metadata":{"id":"8PBgZiaeWbBf","execution":{"iopub.status.busy":"2023-12-20T20:52:17.639549Z","iopub.execute_input":"2023-12-20T20:52:17.639880Z","iopub.status.idle":"2023-12-20T20:52:17.644246Z","shell.execute_reply.started":"2023-12-20T20:52:17.639854Z","shell.execute_reply":"2023-12-20T20:52:17.643333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ConvModel(torch.nn.Module):\n    def __init__(self, output_units):\n        super().__init__()\n        self.conv1 = torch.nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding='same')\n        self.pool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n        self.conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding='same')\n        self.pool2 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n        self.conv3 = torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding='same')\n        self.pool3 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n        self.conv4 = torch.nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding='same')\n        self.pool4 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n        self.fc1 = torch.nn.Linear(in_features=32768, out_features=512)\n        self.fc2 = torch.nn.Linear(in_features=512, out_features=output_units)\n\n    def forward(self, x):\n        x = self.pool1(torch.relu(self.conv1(x)))\n        x = self.pool2(torch.relu(self.conv2(x)))\n        x = self.pool3(torch.relu(self.conv3(x)))\n        x = self.pool4(torch.relu(self.conv4(x)))\n        x = torch.flatten(x, 1)\n        x = torch.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\nconv_model = ConvModel(CANTIDAD_CLASES)","metadata":{"id":"Z-I-L1l3WbBf","execution":{"iopub.status.busy":"2023-12-20T20:52:17.645536Z","iopub.execute_input":"2023-12-20T20:52:17.645898Z","iopub.status.idle":"2023-12-20T20:52:17.794909Z","shell.execute_reply.started":"2023-12-20T20:52:17.645864Z","shell.execute_reply":"2023-12-20T20:52:17.793823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Observemos las versión corta de la arquitectura\nfor name, layer in conv_model.named_children():\n    print(name, layer)","metadata":{"id":"EDuQ1tDbWbBf","execution":{"iopub.status.busy":"2023-12-20T20:52:17.796277Z","iopub.execute_input":"2023-12-20T20:52:17.797086Z","iopub.status.idle":"2023-12-20T20:52:17.802659Z","shell.execute_reply.started":"2023-12-20T20:52:17.797050Z","shell.execute_reply":"2023-12-20T20:52:17.801793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision\nfrom torchvision.transforms import v2\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\n\n# Utilizo la versión v2 de torchvision.transform\ntransform_train = v2.Compose([\n    v2.RandomResizedCrop(256),\n    v2.RandomHorizontalFlip(0.5),\n    v2.ColorJitter(saturation=0.1, hue=0.1),\n    v2.RandomRotation(45),\n    v2.ToTensor(),\n    v2.Normalize(mean=[0.485, 0.456, 0.406],\n                 std=[0.229, 0.224, 0.225]),\n])\n\n# Transformaciones de test\ntransform_test = v2.Compose([\n    v2.Resize(256),\n    v2.CenterCrop(256),\n    v2.ToTensor(),\n    v2.Normalize(mean=[0.485, 0.456, 0.406],\n                 std=[0.229, 0.224, 0.225]),\n])\n\n# Cargo datasets\ntrain_dataset = torchvision.datasets.ImageFolder(\n    root='/kaggle/working/datasets/train',\n    transform=transform_train\n)\ntest_dataset = torchvision.datasets.ImageFolder(\n    root='/kaggle/working/datasets/test',\n    transform=transform_test\n)\n\n# Cargo DataLoaders\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=64,\n    shuffle=True,\n    #sampler=train_sampler,\n    num_workers=4,\n    pin_memory=True\n)\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=64,\n    #sampler=test_sampler,\n    shuffle=True,\n    num_workers=4\n)","metadata":{"id":"WIazZWT2WbBf","execution":{"iopub.status.busy":"2023-12-20T20:52:17.803933Z","iopub.execute_input":"2023-12-20T20:52:17.804248Z","iopub.status.idle":"2023-12-20T20:52:17.832311Z","shell.execute_reply.started":"2023-12-20T20:52:17.804224Z","shell.execute_reply":"2023-12-20T20:52:17.831353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Corremos el entrenamiento\nimport torchmetrics\nfrom torch.utils.tensorboard import SummaryWriter\nimport torch.optim as optim\n\noptimizer = torch.optim.Adam(conv_model.parameters(), lr=0.00025)\nloss = torch.nn.CrossEntropyLoss()\nmetric = torchmetrics.F1Score(task='multiclass', num_classes=num_classes)\ndata = {\"train\": train_loader,\n        \"valid\": test_loader,\n        \"image_width\": 256,\n        \"image_height\": 256}\nepochs = 50\nwriter = {\"train\": SummaryWriter(log_dir=\"transfer_learning_conv/train\"),\n          \"valid\": SummaryWriter(log_dir=\"transfer_learning_conv/valid\")}\n\nhistory = train(conv_model.to('cpu'),\n                optimizer,\n                loss,\n                metric,\n                data,\n                epochs,\n                writer)","metadata":{"id":"Wu8nuMYKWbBf","execution":{"iopub.status.busy":"2023-12-20T20:52:17.833581Z","iopub.execute_input":"2023-12-20T20:52:17.833897Z","iopub.status.idle":"2023-12-20T21:07:02.102651Z","shell.execute_reply.started":"2023-12-20T20:52:17.833872Z","shell.execute_reply":"2023-12-20T21:07:02.101443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ploteo\nfig, axs = plt.subplots(2, 1, figsize=(10, 10))\n\naxs[0].plot(history[\"train_loss\"])\naxs[0].plot(history[\"valid_loss\"])\naxs[0].title.set_text('Error de Entrenamiento vs Validación')\naxs[0].legend(['Train', 'Valid'])\n\naxs[1].plot(history[\"train_met\"])\naxs[1].plot(history[\"valid_met\"])\naxs[1].title.set_text('F1 de Entrenamiento vs Validación')\naxs[1].legend(['Train', 'Valid'])","metadata":{"id":"TwASl84kWbBf","execution":{"iopub.status.busy":"2023-12-20T21:07:02.104574Z","iopub.execute_input":"2023-12-20T21:07:02.105547Z","iopub.status.idle":"2023-12-20T21:07:02.705482Z","shell.execute_reply.started":"2023-12-20T21:07:02.105485Z","shell.execute_reply":"2023-12-20T21:07:02.704181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cargo los mejores parámetros (min loss)\nbest_model_params = torch.load('best_model_params.pth')\nconv_model.load_state_dict(best_model_params)","metadata":{"id":"jeJyTpBcWbBg","execution":{"iopub.status.busy":"2023-12-20T21:07:02.706832Z","iopub.execute_input":"2023-12-20T21:07:02.707151Z","iopub.status.idle":"2023-12-20T21:07:02.779259Z","shell.execute_reply.started":"2023-12-20T21:07:02.707123Z","shell.execute_reply":"2023-12-20T21:07:02.778261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluación del accuracy y Confusion Matrix\nfrom torchmetrics.classification import MulticlassConfusionMatrix\n\nall_labels = []\nall_preds = []\n\n# Todo debe correr en el mismo sitio\ndevice = 'cuda'\n\n# Aseguro el modelo en evaluation\nconv_model.to(device)\nconv_model.eval()\n\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = conv_model(inputs)\n        _, preds = torch.max(outputs, 1)\n\n        all_labels.extend(labels.cpu().numpy())\n        all_preds.extend(preds.cpu().numpy())\n\nconfmat = MulticlassConfusionMatrix(num_classes=num_classes)\nconfmat(torch.tensor(all_preds),\n        torch.tensor(all_labels))","metadata":{"execution":{"iopub.status.busy":"2023-12-20T21:15:17.684980Z","iopub.execute_input":"2023-12-20T21:15:17.685414Z","iopub.status.idle":"2023-12-20T21:15:19.416655Z","shell.execute_reply.started":"2023-12-20T21:15:17.685381Z","shell.execute_reply":"2023-12-20T21:15:19.415340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ploteo la matriz de confusion\nax_ = clases\nfig_, ax_ = confmat.plot()\n\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\n\nax_.set_xticklabels(clases)\nplt.xticks(rotation=45)\nax_.set_yticklabels(clases)\nplt.yticks(rotation=45)\n\nplt.title(\"Confusion Matrix\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-20T21:15:20.385576Z","iopub.execute_input":"2023-12-20T21:15:20.386399Z","iopub.status.idle":"2023-12-20T21:15:20.724568Z","shell.execute_reply.started":"2023-12-20T21:15:20.386366Z","shell.execute_reply":"2023-12-20T21:15:20.723461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluación del accuracy\nconv_model.eval()\n\ncorrectas = 0\ntotal = 0\ndevice = 'cuda'\n\nwith torch.no_grad():\n    for imagenes, etiquetas in test_loader:\n        imagenes, etiquetas = imagenes.to(device), etiquetas.to(device)\n        salidas = conv_model(imagenes)\n        _, predicciones = torch.max(salidas.data, 1)\n        total += etiquetas.size(0)\n        correctas += (predicciones == etiquetas).sum().item()\n\n# Calcular el accuracy\naccuracy = correctas / total\nprint(f'Accuracy en el conjunto de pruebas: {accuracy * 100:.2f}%')","metadata":{"id":"gPCZLcSmWbBg","execution":{"iopub.status.busy":"2023-12-20T21:07:02.780420Z","iopub.execute_input":"2023-12-20T21:07:02.780696Z","iopub.status.idle":"2023-12-20T21:07:04.553005Z","shell.execute_reply.started":"2023-12-20T21:07:02.780665Z","shell.execute_reply":"2023-12-20T21:07:04.551651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conv_model.eval()  # Asegurarte de que el modelo esté en modo de evaluación\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nconv_model.to(device)\n\ncorrect_predictions_per_class = {i: 0 for i in range(num_classes)}\ntotal_samples_per_class = {i: 0 for i in range(num_classes)}\n\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        outputs = conv_model(inputs)\n        _, predicted_classes = torch.max(outputs, 1)\n\n        for i in range(len(labels)):\n            label = labels[i].item()\n            prediction = predicted_classes[i].item()\n            total_samples_per_class[label] += 1\n            correct_predictions_per_class[label] += int(label == prediction)\n\nclass_accuracies = {}\nfor class_label, correct_predictions in correct_predictions_per_class.items():\n    total_samples = total_samples_per_class[class_label]\n    accuracy = correct_predictions / total_samples if total_samples > 0 else 0.0\n    class_accuracies[class_label] = accuracy\n\nfor class_label, accuracy in class_accuracies.items():\n    print(f'Accuracy for Class {clases[class_label]}: {accuracy:.2%}')","metadata":{"id":"sRWAEQ91WbBg","execution":{"iopub.status.busy":"2023-12-20T21:07:04.554794Z","iopub.execute_input":"2023-12-20T21:07:04.555177Z","iopub.status.idle":"2023-12-20T21:07:06.261991Z","shell.execute_reply.started":"2023-12-20T21:07:04.555143Z","shell.execute_reply":"2023-12-20T21:07:06.260691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Salvo el modelo y el estado del optimizador\nruta_modelo_completo = '/kaggle/working/conv'\ntorch.save({\n    'modelo_estado_dict': conv_model.state_dict(),\n    'optimizador_estado_dict': optimizer.state_dict(),\n}, ruta_modelo_completo)","metadata":{"id":"tzRXom_FWbBg","execution":{"iopub.status.busy":"2023-12-20T21:07:06.263717Z","iopub.execute_input":"2023-12-20T21:07:06.264076Z","iopub.status.idle":"2023-12-20T21:07:06.561039Z","shell.execute_reply.started":"2023-12-20T21:07:06.264044Z","shell.execute_reply":"2023-12-20T21:07:06.560003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### **4. CONCLUSIONES**\n\n- Los modelos evaluados con transfer learning han performado pobremente, para obtener una buena performance uno debería reentrenar los pesos de toda la red porque parece haber Negative Transfer Learning. Los modelos fueron entrenados en datasets muy diferentes al utilizado en este trabajo, las capas preentrenadas no aportan significativamente a las predicciones del modelo, que en su capa lineal copia los datos mayoritarios, una red convolucional sencilla performa mejor que las redes profundas.\n- El desbalance del DataSet es demasiado marcado, por más que se afecte el sampler, hay una gran diferencia entre la cantidad de veces que el modelo ve las imágenes de cada clase y termina repercutiendo en el resultado.\n- Para obtener un buen desempeño, se debe balancear el dataset y entrenar un modelo desde cero con su respectivo costo computacional. El ideal parece ser trabajar con segmentación semántica, eliminando los errores provenientes del fondo y del pelo.","metadata":{"id":"LVCCJ9hAWbBg"}},{"cell_type":"code","source":"","metadata":{"id":"oraOQt-jWbBg"},"execution_count":null,"outputs":[]}]}